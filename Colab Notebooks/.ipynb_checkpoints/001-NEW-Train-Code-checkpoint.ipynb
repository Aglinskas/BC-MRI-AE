{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce60182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime;now = datetime.now;t00 = now()\n",
    "print(t00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe910ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU checks\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU checks\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82768686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU checks\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from importlib import reload\n",
    "from helper_funcs import *\n",
    "from make_models2 import *\n",
    "\n",
    "# Make tqdm work for notebooks\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "tqdm = partial(tqdm, position=0, leave=True)\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "\n",
    "print(now()-t00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46129bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GPU test\n",
    "import tensorflow as tf\n",
    "import timeit,pickle\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b643a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD Data\n",
    "arr = np.load('../Data/ABIDE-Anat-64iso-S982_v2.npz')\n",
    "ABIDE_data = arr['data']\n",
    "ABIDE_subs = arr['subs']\n",
    "nsubs = ABIDE_data.shape[0]\n",
    "print([arr.shape for arr in [ABIDE_subs,ABIDE_data]])\n",
    "print((ABIDE_data.min(),ABIDE_data.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2487d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Legend\n",
    "df = pd.read_csv('../CSVs/ABIDE-legend.csv',header=0)\n",
    "df = df.iloc[np.array([df['BIDS_ID'].values[s] in ABIDE_subs for s in range(len(df))])]\n",
    "df.reset_index(inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "assert len(df)==len(ABIDE_subs),'lenght mismatch'\n",
    "assert all([df['BIDS_ID'][s]==ABIDE_subs[s] for s in range(len(df))]),'order mismatch'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bbffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = df['DxGroup'].values==1\n",
    "controls = df['DxGroup'].values==2\n",
    "\n",
    "TD_subs = ABIDE_data[controls,:,:,:] # Data of Typically Developing participants \n",
    "DX_subs = ABIDE_data[patients,:,:,:] # Data of ASD participants\n",
    "\n",
    "print(TD_subs.shape)\n",
    "print(DX_subs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8864c6",
   "metadata": {},
   "source": [
    "### TRAIN VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbaae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vae = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_vae:\n",
    "    \n",
    "    latent_dim = 32\n",
    "    batch_size = 16\n",
    "    disentangle = False\n",
    "    gamma = 100\n",
    "\n",
    "    encoder, decoder, vae = get_MRI_VAE_3D(input_shape=(64,64,64,1), \n",
    "                                            latent_dim=32, \n",
    "                                            batch_size = batch_size, \n",
    "                                            disentangle=True,\n",
    "                                            gamma=gamma,\n",
    "                                            kernel_size = 3,\n",
    "                                            filters = 48,\n",
    "                                            intermediate_dim = 128,\n",
    "                                            nlayers = 2,\n",
    "                                            bias=True)\n",
    "\n",
    "\n",
    "    loss = list()\n",
    "    fn = '../../tf_outputs/VAE/VAE_weights'\n",
    "        \n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c602dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbatches = int(1e6)\n",
    "nbatches = 6\n",
    "if train_vae:\n",
    "    for i in tqdm(range(1,nbatches)):    \n",
    "        \n",
    "        batch_idx = np.random.randint(low=0,high=ABIDE_data.shape[0],size=batch_size)\n",
    "        data_batch = ABIDE_data[batch_idx,:,:,:]\n",
    "        \n",
    "        history = vae.train_on_batch(data_batch);\n",
    "        mse = ((data_batch-vae.predict(data_batch)[:,:,:,:,0])**2).mean()\n",
    "        loss.append(history);\n",
    "        \n",
    "        if np.mod(i,5)==0: # Plot training progress\n",
    "            im1 = data_batch[0,32,:,:];\n",
    "            im = vae.predict(data_batch)[0,32,:,:,0];\n",
    "            plot_trainProgress(loss,im,im1);\n",
    "\n",
    "        if np.mod(i,100)==0: # Save every 100 batches\n",
    "            pickle.dump(loss,open(fn+'_loss.pickle','wb'))\n",
    "            vae.save_weights(fn)    \n",
    "        \n",
    "        if mse < .005:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5285310",
   "metadata": {},
   "source": [
    "### TRAIN CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cvae = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_cvae:\n",
    "    \n",
    "    latent_dim = 16\n",
    "    batch_size = 16\n",
    "    beta = 1;gamma = 100\n",
    "    disentangle = True\n",
    "    cvae, z_encoder, s_encoder, cvae_decoder = get_MRI_CVAE_3D(latent_dim=latent_dim,beta=beta, disentangle=disentangle, gamma=gamma, bias=True, batch_size = batch_size)\n",
    "    loss = list()    \n",
    "    \n",
    "    fdir = '../../tf_outputs/CVAE/'\n",
    "    fn = 'CVAE_weights'\n",
    "    \n",
    "    fn = os.path.join(fdir,fn)\n",
    "    loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5afce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_encoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1014e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_decoder.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23176237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a5554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2061dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial check\n",
    "DX_batch = DX_subs[np.random.randint(low=0,high=DX_subs.shape[0],size=batch_size),:,:,:];\n",
    "TD_batch = TD_subs[np.random.randint(low=0,high=TD_subs.shape[0],size=batch_size),:,:,:];\n",
    "\n",
    "if len(loss)==0:\n",
    "    loss.append(np.nan)\n",
    "    im,im1,ss = cvae_query(ABIDE_data,s_encoder,z_encoder,cvae_decoder);\n",
    "    plot_trainProgress(loss,im,im1);\n",
    "    loss = list()\n",
    "else:\n",
    "    im,im1,ss = cvae_query(ABIDE_data,s_encoder,z_encoder,cvae_decoder);\n",
    "    plot_trainProgress(loss,im,im1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d60afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbatches = 6\n",
    "if train_cvae:\n",
    "    for i in tqdm(range(1,nbatches)):\n",
    "        \n",
    "        DX_batch = DX_subs[np.random.randint(low=0,high=DX_subs.shape[0],size=batch_size),:,:,:];\n",
    "        TD_batch = TD_subs[np.random.randint(low=0,high=TD_subs.shape[0],size=batch_size),:,:,:];\n",
    "        \n",
    "        hist = cvae.train_on_batch([DX_batch,TD_batch]);\n",
    "        loss.append(hist);\n",
    "        \n",
    "        mse = ((np.array([DX_batch,TD_batch])-np.array(cvae.predict([DX_batch,TD_batch]))[:,:,:,:,:,0])**2).mean()\n",
    "\n",
    "        assert not np.isnan(hist),'loss is NaN - somethings wrong'\n",
    "\n",
    "        im,im1,ss = cvae_query(ABIDE_data, s_encoder, z_encoder, cvae_decoder); \n",
    "\n",
    "        \n",
    "\n",
    "        if np.mod(i,5)==0: # Plot training progress\n",
    "            plot_trainProgress(loss,im,im1);\n",
    "            pickle.dump(loss,open(fn+'_loss.pickle','wb'))\n",
    "            plot_four(DX_batch, TD_batch, z_encoder, s_encoder,cvae_decoder,cvae,idx=0)\n",
    "            plot_four(DX_batch, TD_batch, z_encoder, s_encoder,cvae_decoder,cvae,idx=1)\n",
    "\n",
    "        if np.mod(i,101)==0: # Save every 100 batches\n",
    "            cvae.save_weights(fn)\n",
    "            \n",
    "        if mse < .005:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2cbcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb041dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6ba37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295b0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6d12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733e11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806f948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e397441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd3635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e155c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9a3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36969d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d65c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e11ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c2992f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d6b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d2a24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee2436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

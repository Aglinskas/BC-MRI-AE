{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4421,
     "status": "ok",
     "timestamp": 1604428889854,
     "user": {
      "displayName": "Aidas Aglinskas",
      "photoUrl": "",
      "userId": "17395860064084454693"
     },
     "user_tz": -60
    },
    "id": "tcKhM_dFrRry"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime;now = datetime.now;t00=now();\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23181,
     "status": "ok",
     "timestamp": 1604428908622,
     "user": {
      "displayName": "Aidas Aglinskas",
      "photoUrl": "",
      "userId": "17395860064084454693"
     },
     "user_tz": -60
    },
    "id": "620FMFj_rWdb",
    "outputId": "3b0b19ba-6d2e-464a-a112-9a0d38890229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "done, mounted\n",
      "2020-11-03 18:41:47.991837\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "print('done, mounted')\n",
    "cd '/content/drive/My Drive/BC-MRI-AE'\n",
    "print(now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23177,
     "status": "ok",
     "timestamp": 1604428908623,
     "user": {
      "displayName": "Aidas Aglinskas",
      "photoUrl": "",
      "userId": "17395860064084454693"
     },
     "user_tz": -60
    },
    "id": "2jGQckUZXsHc",
    "outputId": "242db4a3-8ba8-4b60-e1d0-c09c906bd721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/BC-MRI-AE\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBLLuPverWf6",
    "outputId": "3fc6b08a-b646-4904-c5bb-0b2756259028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    }
   ],
   "source": [
    "# ABIDE-64iso-normed\n",
    "# SFARI-64iso-normed\n",
    "print('loading data');t0 = now()\n",
    "def load_data(data_dir):\n",
    "  #data_dir = './Data/ABIDE-64iso-normed'\n",
    "  files = [file for file in os.listdir(data_dir) if '.npy' in file]; files.sort()\n",
    "  data = np.array([np.load(os.path.join(data_dir,file)) for file in files])\n",
    "  return data\n",
    "\n",
    "#data_validation = load_data('./Data/SFARI-64iso-normed');print(data_validation.shape)\n",
    "#data_validation = data_validation[:,np.newaxis,:,:,:]\n",
    "\n",
    "data = load_data('./Data/ABIDE-64iso-normed');print(data.shape)\n",
    "data = data[:,np.newaxis,:,:,:]\n",
    "\n",
    "print(f\"loaded in {now()-t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-jigISMrWiM"
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LDf7Y80VeIR"
   },
   "outputs": [],
   "source": [
    "# Autoencoder class\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self,input_shape,k=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Stuff\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = input_shape[0]\n",
    "\n",
    "        self.lrelu = torch.nn.LeakyReLU(negative_slope=.02)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "\n",
    "        # Shapes and sizes\n",
    "        #R = np.ones(shape=self.input_shape)\n",
    "        #R = torch.tensor(R).float()\n",
    "\n",
    "        bias_bool = False # Do you want padding or not \n",
    "\n",
    "        # Encoder\n",
    "        self.enc_C1 = nn.Conv3d(in_channels=1,out_channels=int(4*k),kernel_size=5, stride=2, padding=2, bias=bias_bool)\n",
    "        self.enc_C2 = nn.Conv3d(in_channels=int(4*k),out_channels=int(8*k),kernel_size=5, stride=2, padding=2, bias=bias_bool)\n",
    "        self.enc_C3 = nn.Conv3d(in_channels=int(8*k),out_channels=int(16*k),kernel_size=5, stride=2, padding=2, bias=bias_bool)\n",
    "        self.enc_C4 = nn.Conv3d(in_channels=int(16*k),out_channels=int(32*k),kernel_size=5, stride=2, padding=2, bias=bias_bool)\n",
    "        self.enc_C5 = nn.Conv3d(in_channels=int(32*k),out_channels=int(64*k),kernel_size=5, stride=2, padding=2, bias=bias_bool)\n",
    "\n",
    "        self.batchNormE1 = nn.BatchNorm3d(int(4*k), affine=False)\n",
    "        self.batchNormE2 = nn.BatchNorm3d(int(8*k), affine=False)\n",
    "        self.batchNormE3 = nn.BatchNorm3d(int(16*k), affine=False)\n",
    "        self.batchNormE4 = nn.BatchNorm3d(int(32*k), affine=False)\n",
    "        self.batchNormE5 = nn.BatchNorm3d(int(64*k), affine=False)\n",
    "\n",
    "        self.batchNormD1 = nn.BatchNorm3d(int(32*k), affine=False)\n",
    "        self.batchNormD2 = nn.BatchNorm3d(int(16*k), affine=False)\n",
    "        self.batchNormD3 = nn.BatchNorm3d(int(8*k), affine=False)\n",
    "        self.batchNormD4 = nn.BatchNorm3d(int(4*k), affine=False)\n",
    "        #self.batchNormD5 = nn.BatchNorm3d(int(4*k), affine=False)\n",
    "\n",
    "        self.dec_C1 = nn.ConvTranspose3d(in_channels=int(64*k),out_channels=int(32*k),kernel_size=4, stride=2, padding=1,bias=bias_bool)\n",
    "        self.dec_C2 = nn.ConvTranspose3d(in_channels=int(32*k),out_channels=int(16*k),kernel_size=4, stride=2, padding=1,bias=bias_bool) \n",
    "        self.dec_C3 = nn.ConvTranspose3d(in_channels=int(16*k),out_channels=int(8*k),kernel_size=4, stride=2, padding=1,bias=bias_bool)\n",
    "        self.dec_C4 = nn.ConvTranspose3d(in_channels=int(8*k),out_channels=int(4*k),kernel_size=4, stride=2, padding=1,bias=bias_bool)\n",
    "        self.dec_C5 = nn.ConvTranspose3d(in_channels=int(4*k),out_channels=1,kernel_size=4, stride=2, padding=1,bias=bias_bool)\n",
    "\n",
    "    def forward(self,hello):\n",
    "      \n",
    "        activation = self.relu( self.enc_C1(hello) )\n",
    "        activation = self.batchNormE1(activation)\n",
    "\n",
    "        activation = self.relu( self.enc_C2(activation) )\n",
    "        activation = self.batchNormE2(activation)\n",
    "\n",
    "        activation = self.relu( self.enc_C3(activation) )\n",
    "        activation = self.batchNormE3(activation)\n",
    "\n",
    "        activation = self.relu( self.enc_C4(activation) )\n",
    "        activation = self.batchNormE4(activation)\n",
    "\n",
    "        activation = self.relu( self.enc_C5(activation) )\n",
    "        activation = self.batchNormE5(activation)\n",
    "\n",
    "        activation = self.relu( self.dec_C1(activation))\n",
    "        activation = self.batchNormD1(activation)\n",
    "\n",
    "        activation = self.relu( self.dec_C2(activation) )\n",
    "        activation = self.batchNormD2(activation)\n",
    "\n",
    "        activation = self.relu( self.dec_C3(activation) )\n",
    "        activation = self.batchNormD3(activation)\n",
    "\n",
    "        activation = self.relu( self.dec_C4(activation) )\n",
    "        activation = self.batchNormD4(activation)\n",
    "\n",
    "        activation = self.sigmoid( self.dec_C5(activation) )\n",
    "        #activation = self.batchNormD5(activation)\n",
    "\n",
    "        return activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LzAMeaRk_i4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVN1AhoorWnX"
   },
   "outputs": [],
   "source": [
    "## Convert data \n",
    "D = torch.tensor(data[:,:,:,:,:]).float()\n",
    "data_batch = D[0:5,:,:,:,:]\n",
    "#D = D[0:10,:,:,:,:]\n",
    "\n",
    "## Model Definition\n",
    "model = CAE(data_batch.shape,k=25) # Initiate mode\n",
    "\n",
    "latentSpaceSize = model.enc_C5(model.enc_C4(model.enc_C3(model.enc_C2(model.enc_C1(data_batch))))).shape\n",
    "print(f\"latentSpaceSize: {latentSpaceSize}\")\n",
    "latentSpaceDim = np.prod(latentSpaceSize)\n",
    "print(f\"latentSpaceDim: {latentSpaceDim/latentSpaceSize[0]}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #  use gpu if available\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform_rule(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "# create a new model with these weights\n",
    "model.apply(weights_init_uniform_rule)\n",
    "\n",
    "#model.to(device)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3,)\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01,weight_decay=.01)\n",
    "#optimizer = optim.SGD(model.parameters(),lr=.001,weight_decay=.0,momentum=.0)\n",
    "#optimizer = optim.RMSprop(model.parameters(),lr=.1)\n",
    "#criterion = nn.MSELoss()\n",
    "print(device)\n",
    "\n",
    "## Training Parameters\n",
    "num_epochs = 501\n",
    "batch_size = 5\n",
    "ndata = data.shape[0]\n",
    "n_batches = np.floor(D.shape[0]/5)\n",
    "batches = np.array([np.arange((i)*5,(i+1)*5) for i in range(int(n_batches))])\n",
    "#D = D.cuda()\n",
    "track = list();\n",
    "\n",
    "ofdir = os.path.join(os.path.curdir,'drive','My Drive','BC-MRI-AE','models')\n",
    "print(ofdir)\n",
    "\n",
    "session_name = 'test'\n",
    "\n",
    "print(n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huIVu0IssnT3"
   },
   "outputs": [],
   "source": [
    "def myLoss(outputs,data_batch):\n",
    "  return torch.sum(torch.square(outputs.view(-1)-data_batch.view(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sij_4vFNd_Pj"
   },
   "outputs": [],
   "source": [
    "int(n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxANZpAhrjES"
   },
   "outputs": [],
   "source": [
    "t0 = datetime.now();\n",
    "for epoch in range(int(num_epochs)):\n",
    "    permutation = np.random.permutation(ndata)\n",
    "    D = D[permutation,:,:,:,:]\n",
    "    for batch_idx in range(int(n_batches)):\n",
    "        optimizer.zero_grad()\n",
    "        data_batch = D[batches[batch_idx,:],:,:,:,:]\n",
    "        outputs = model.forward(data_batch)\n",
    "        #train_loss = criterion(outputs,data_batch)\n",
    "        train_loss = myLoss(outputs,data_batch)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        track.append(train_loss.item())\n",
    "        if batch_idx%50==0:\n",
    "          print(f\"epoch {epoch}/{num_epochs} | batch {batch_idx}/{n_batches} | time {str(datetime.now()-t0)} | loss {round(train_loss.item(),5)}\")\n",
    "\n",
    "\n",
    "    track = track[-min(len(track),10000)::]\n",
    "\n",
    "    if epoch%100==0:\n",
    "      ofn = os.path.join(ofdir,f'{session_name}' + f'e{epoch}_'+str(now()))\n",
    "      print('saved')\n",
    "      print(ofn)\n",
    "      #torch.save(model.state_dict(),ofn)\n",
    "     \n",
    "    if epoch%5==0:\n",
    "      print(outputs.view(-1))\n",
    "      plt.figure()\n",
    "      plt.subplot(1,2,1)\n",
    "      plt.imshow(data_batch.cpu().detach().numpy()[0,0,32,:,:])\n",
    "      plt.subplot(1,2,2)\n",
    "      plt.imshow(outputs.cpu().detach().numpy()[0,0,32,:,:])\n",
    "      plt.show()\n",
    "\n",
    "      plt.figure(figsize=(10,3))\n",
    "      plt.subplot(1,2,1)\n",
    "      t = track\n",
    "      plt.plot(t)\n",
    "      plt.title('training acc')\n",
    "\n",
    "      xs = np.arange(len(t))+1\n",
    "      z = np.polyfit(xs, t, 1)\n",
    "      p = np.poly1d(z)\n",
    "      plt.subplot(1,2,2)\n",
    "      plt.plot(xs,p(xs),\"r--\")\n",
    "      plt.title('trend')\n",
    "\n",
    "\n",
    "      b = outputs.cpu().detach()\n",
    "      a = data_batch.cpu().detach()\n",
    "      plt.figure(figsize=(10,3))\n",
    "      plt.subplot(1,2,1)\n",
    "      sns.distplot(np.array(b[a>0.001]).flatten())\n",
    "      plt.title('Predicted')\n",
    "      plt.subplot(1,2,2)\n",
    "      sns.distplot(np.array(a[a>0.001]).flatten())\n",
    "      plt.title('True')\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgxrGEzx2lNL"
   },
   "outputs": [],
   "source": [
    " %print('all done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnOikCDDce_a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5PAnJczcfBv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjXikoR3dceV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ScuYMrjLpo-p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YK6plvnXppA3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k39o6LekppDS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQSmgau7ppFt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lYXwfqUppIC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Prh1klboppKr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlnFRVNIppNi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkGPm4iMppQH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOSmvdDw17kx/kfPa5tTP2J",
   "collapsed_sections": [],
   "name": "MRI-CAE-MAIN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

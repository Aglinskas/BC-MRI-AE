{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_celeb_cvae(input_shape=(28, 28, 3), latent_dim=2, beta=1, disentangle=False, gamma=1, bias=True):\n",
    "    \n",
    "    image_size, _, channels = input_shape\n",
    "    batch_size = 64\n",
    "    kernel_size = 3\n",
    "    filters = 16\n",
    "    intermediate_dim = 128\n",
    "    epochs = 10\n",
    "\n",
    "    # build encoder model\n",
    "    tg_inputs = Input(shape=input_shape, name='tg_inputs')\n",
    "    bg_inputs = Input(shape=input_shape, name='bg_inputs')\n",
    "\n",
    "    z_conv1 = Conv2D(filters=filters*2,\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "               use_bias=bias,\n",
    "               padding='same')\n",
    "    z_conv2 = Conv2D(filters=filters*4,\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "               use_bias=bias,\n",
    "               padding='same')\n",
    "\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    z_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias)\n",
    "    z_mean_layer = Dense(latent_dim, name='z_mean', use_bias=bias)\n",
    "    z_log_var_layer = Dense(latent_dim, name='z_log_var', use_bias=bias)\n",
    "    z_layer = Lambda(sampling, output_shape=(latent_dim,), name='z')\n",
    "    \n",
    "    def z_encoder_func(inputs):\n",
    "        z_h = inputs\n",
    "        z_h = z_conv1(z_h)\n",
    "        z_h = z_conv2(z_h)\n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(z_h)\n",
    "        z_h = Flatten()(z_h)\n",
    "        z_h = z_h_layer(z_h)\n",
    "        z_mean =  z_mean_layer(z_h)\n",
    "        z_log_var =  z_log_var_layer(z_h)\n",
    "        z = z_layer([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z, shape\n",
    "\n",
    "    tg_z_mean, tg_z_log_var, tg_z, shape_z = z_encoder_func(tg_inputs)\n",
    "    \n",
    "    \n",
    "    s_conv1 = Conv2D(filters=filters*2,\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "               use_bias=bias,\n",
    "               padding='same')\n",
    "    s_conv2 = Conv2D(filters=filters*4,\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "               use_bias=bias,\n",
    "               padding='same')\n",
    "\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    s_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias)\n",
    "    s_mean_layer = Dense(latent_dim, name='s_mean', use_bias=bias)\n",
    "    s_log_var_layer = Dense(latent_dim, name='s_log_var', use_bias=bias)\n",
    "    s_layer = Lambda(sampling, output_shape=(latent_dim,), name='s')\n",
    "    \n",
    "    def s_encoder_func(inputs):\n",
    "        s_h = inputs\n",
    "        s_h = s_conv1(s_h)\n",
    "        s_h = s_conv2(s_h)\n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(s_h)\n",
    "        s_h = Flatten()(s_h)\n",
    "        s_h = s_h_layer(s_h)\n",
    "        s_mean =  s_mean_layer(s_h)\n",
    "        s_log_var =  s_log_var_layer(s_h)\n",
    "        s = s_layer([s_mean, s_log_var])\n",
    "        return s_mean, s_log_var, s, shape\n",
    "\n",
    "    tg_s_mean, tg_s_log_var, tg_s, shape_s = s_encoder_func(tg_inputs)\n",
    "    bg_s_mean, bg_s_log_var, bg_s, _ = s_encoder_func(bg_inputs)\n",
    "    \n",
    "\n",
    "    # instantiate encoder models\n",
    "    z_encoder = tf.keras.models.Model(tg_inputs, [tg_z_mean, tg_z_log_var, tg_z], name='z_encoder')\n",
    "    s_encoder = tf.keras.models.Model(tg_inputs, [tg_s_mean, tg_s_log_var, tg_s], name='s_encoder')\n",
    "\n",
    "    # build decoder model\n",
    "    print(shape_z)\n",
    "    latent_inputs = Input(shape=(2*latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu', use_bias=bias)(latent_inputs)\n",
    "    x = Dense(shape_z[1] * shape_z[2] * shape_z[3], activation='relu', use_bias=bias)(x)\n",
    "    x = Reshape((shape_z[1], shape_z[2], shape_z[3]))(x)\n",
    "\n",
    "    for i in range(2):\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='relu',\n",
    "                            strides=2,\n",
    "                            use_bias=bias,\n",
    "                            padding='same')(x)\n",
    "        filters //= 2\n",
    "\n",
    "    outputs = Conv2DTranspose(filters=3,\n",
    "                              kernel_size=kernel_size,\n",
    "                              activation='sigmoid',\n",
    "                              padding='same',\n",
    "                              use_bias=bias,\n",
    "                              name='decoder_output')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    cvae_decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    # decoder.summary()\n",
    "\n",
    "    def zeros_like(x):\n",
    "        return tf.zeros_like(x)\n",
    "\n",
    "    tg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, tg_s], -1))\n",
    "    zeros = tf.keras.layers.Lambda(zeros_like)(tg_z)\n",
    "    bg_outputs = cvae_decoder(tf.keras.layers.concatenate([zeros, bg_s], -1))\n",
    "    fg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, zeros], -1))\n",
    "\n",
    "    # instantiate VAE model\n",
    "    cvae = tf.keras.models.Model(inputs=[tg_inputs, bg_inputs], \n",
    "                                 outputs=[tg_outputs, bg_outputs], \n",
    "                                 name='contrastive_vae')\n",
    "\n",
    "    cvae_fg = tf.keras.models.Model(inputs=tg_inputs, \n",
    "                                    outputs=fg_outputs, \n",
    "                                    name='contrastive_vae_fg')\n",
    "    \n",
    "    if disentangle:\n",
    "        discriminator = Dense(1, activation='sigmoid')\n",
    "        \n",
    "        z1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_z)\n",
    "        z2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_z)\n",
    "        s1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_s)\n",
    "        s2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_s)\n",
    "        q_bar = tf.keras.layers.concatenate(\n",
    "            [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "            tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "            axis=0)\n",
    "        q = tf.keras.layers.concatenate(\n",
    "            [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "            tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "            axis=0)\n",
    "        q_bar_score = discriminator(q_bar)\n",
    "        q_score = discriminator(q)        \n",
    "        tc_loss = K.log(q_score / (1 - q_score)) \n",
    "        \n",
    "        discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "    else:\n",
    "        tc_loss = 0\n",
    "        discriminator_loss = 0\n",
    "    \n",
    "    \n",
    "    reconstruction_loss = tf.keras.losses.mse(K.flatten(tg_inputs), K.flatten(tg_outputs))\n",
    "    reconstruction_loss += tf.keras.losses.mse(K.flatten(bg_inputs), K.flatten(bg_outputs))\n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1] * input_shape[2]\n",
    "\n",
    "\n",
    "    kl_loss = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    kl_loss += 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    kl_loss += 1 + bg_s_log_var - tf.keras.backend.square(bg_s_mean) - tf.keras.backend.exp(bg_s_log_var)\n",
    "    kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "\n",
    "    cvae_loss = tf.keras.backend.mean(reconstruction_loss + beta*kl_loss + gamma * tc_loss + discriminator_loss)\n",
    "    cvae.add_loss(cvae_loss)\n",
    "    cvae.compile(optimizer='rmsprop')\n",
    "    \n",
    "    return cvae, cvae_fg, z_encoder, s_encoder, cvae_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "cvae, cvae_fg, z_encoder, s_encoder, cvae_decoder = get_celeb_cvae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

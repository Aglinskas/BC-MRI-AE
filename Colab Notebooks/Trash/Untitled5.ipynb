{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anatomical nifti image (3D) is located at: /Users/aidasaglinskas/nilearn_data/haxby2001/mask.nii.gz\n",
      "Functional nifti image (4D) is located at: /Users/aidasaglinskas/nilearn_data/haxby2001/subj2/bold.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nilearn import datasets\n",
    "from nilearn.image import new_img_like, load_img, get_data\n",
    "\n",
    "# We fetch 2nd subject from haxby datasets (which is default)\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "\n",
    "# print basic information on the dataset\n",
    "print('Anatomical nifti image (3D) is located at: %s' % haxby_dataset.mask)\n",
    "print('Functional nifti image (4D) is located at: %s' % haxby_dataset.func[0])\n",
    "\n",
    "fmri_filename = haxby_dataset.func[0]\n",
    "labels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "y = labels['labels']\n",
    "session = labels['chunks']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import index_img\n",
    "condition_mask = y.isin(['face', 'house'])\n",
    "\n",
    "fmri_img = index_img(fmri_filename, condition_mask)\n",
    "y, session = y[condition_mask], session[condition_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask_img = load_img(haxby_dataset.mask)\n",
    "\n",
    "# .astype() makes a copy.\n",
    "process_mask = get_data(mask_img).astype(np.int)\n",
    "picked_slice = 29\n",
    "process_mask[..., (picked_slice + 1):] = 0\n",
    "process_mask[..., :picked_slice] = 0\n",
    "process_mask[:, 30:] = 0\n",
    "process_mask_img = new_img_like(mask_img, process_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidasaglinskas/opt/anaconda3/envs/py3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SearchLight(cv=KFold(n_splits=4, random_state=None, shuffle=False),\n",
       "            estimator='svc',\n",
       "            mask_img=<nibabel.nifti1.Nifti1Image object at 0x7f8fd4e9aad0>,\n",
       "            n_jobs=1,\n",
       "            process_mask_img=<nibabel.nifti1.Nifti1Image object at 0x7f8fd4e57790>,\n",
       "            radius=5.6, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# /!\\ As each thread will print its progress, n_jobs > 1 could mess up the\n",
    "#     information output.\n",
    "n_jobs = 1\n",
    "\n",
    "# Define the cross-validation scheme used for validation.\n",
    "# Here we use a KFold cross-validation on the session, which corresponds to\n",
    "# splitting the samples in 4 folds and make 4 runs using each fold as a test\n",
    "# set once and the others as learning sets\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=4)\n",
    "\n",
    "import nilearn.decoding\n",
    "# The radius is the one of the Searchlight sphere that will scan the volume\n",
    "searchlight = nilearn.decoding.SearchLight(\n",
    "    mask_img,\n",
    "    process_mask_img=process_mask_img,\n",
    "    radius=5.6, n_jobs=n_jobs,\n",
    "    verbose=1, cv=cv)\n",
    "\n",
    "searchlight.fit(fmri_img, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'mask_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7c210ea522ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSearchLight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'mask_img'"
     ]
    }
   ],
   "source": [
    "nilearn.decoding.SearchLight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "# For decoding, standardizing is often very important\n",
    "nifti_masker = NiftiMasker(mask_img=mask_img, sessions=session,\n",
    "                           standardize=True, memory='nilearn_cache',\n",
    "                           memory_level=1)\n",
    "fmri_masked = nifti_masker.fit_transform(fmri_img)\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "f_values, p_values = f_classif(fmri_masked, y)\n",
    "p_values = -np.log10(p_values)\n",
    "p_values[p_values > 10] = 10\n",
    "p_unmasked = get_data(nifti_masker.inverse_transform(p_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-41e2d18045be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_fmri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmri_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_stat_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msearchlight_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_img_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_fmri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchlight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "mean_fmri = image.mean_img(fmri_img)\n",
    "\n",
    "from nilearn.plotting import plot_stat_map, plot_img, show\n",
    "searchlight_img = new_img_like(mean_fmri, searchlight.scores_)\n",
    "\n",
    "# Because scores are not a zero-center test statistics, we cannot use\n",
    "# plot_stat_map\n",
    "plot_img(searchlight_img, bg_img=mean_fmri,\n",
    "         title=\"Searchlight\", display_mode=\"z\", cut_coords=[-9],\n",
    "         vmin=.42, cmap='hot', threshold=.2, black_bg=True)\n",
    "\n",
    "# F_score results\n",
    "p_ma = np.ma.array(p_unmasked, mask=np.logical_not(process_mask))\n",
    "f_score_img = new_img_like(mean_fmri, p_ma)\n",
    "plot_stat_map(f_score_img, mean_fmri,\n",
    "              title=\"F-scores\", display_mode=\"z\",\n",
    "              cut_coords=[-9],\n",
    "              colorbar=False)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
